---
title: "R Notebook"
output: html_notebook
---

```{r}
library(mosaic)
library(mosaicData)
library(tidyverse)
library(janitor)
library(GGally)
library(ggfortify)
```
 # price price in US dollars (\$326--\$18,823)
carat weight of the diamond (0.2--5.01)
cut quality of the cut (Fair, Good, Very Good, Premium, Ideal)
color diamond colour, from J (worst) to D (best)
clarity a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))
x length in mm (0--10.74)
y width in mm (0--58.9)
z depth in mm (0--31.8)
depth total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43--79)
table width of top of diamond relative to widest point (43--95)

# 1. Load the diamonds.csv data set and undertake an initial exploration of the data. You will find a description of the meanings of the variables on the relevant Kaggle page

```{r}
diamonds <- diamonds
```
 
 
# 2. We expect the carat of the diamonds to be strong correlated with the physical dimensions x, y and z. Use ggpairs() to investigate correlations between these four variables. 

```{r}
ggpairs(diamonds)
```
 
 
# 3. So, we do find significant correlations. Let’s drop columns x, y and z from the dataset, in preparation to use only carat going forward.

```{r}
diamonds_trim <- diamonds %>%
  select(-c("x", "y", "z"))
```
 
 
# 4. We are interested in developing a regression model for the price of a diamond in terms of the possible predictor variables in the dataset.
i Use ggpairs() to investigate correlations between price and the predictors (this may take a while to run, don’t worry, make coffee or something).

 
```{r}
ggpairs(diamonds_trim)
```

# Perform further ggplot visualisations of any significant correlations you find.

```{r}
diamonds_trim %>%
  ggplot(aes(x = carat, y = price)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
```
# 5. Shortly we may try a regression fit using one or more of the categorical predictors cut, clarity and color, so let’s investigate these predictors:
i Investigate the factor levels of these predictors. How many dummy variables do you expect for each of them?


```{r}
unique(diamonds_trim$cut)
```
```{r}
unique(diamonds_trim$clarity)
```

```{r}
unique(diamonds_trim$color)
```


# ii Use the dummy_cols() function in the fastDummies package to generate dummies for these predictors and check the number of dummies in each case.

```{r}
diamonds_dummy <- diamonds_trim %>%
  fastDummies::dummy_cols(select_columns = "cut", remove_first_dummy = TRUE) %>%
  fastDummies::dummy_cols(select_columns = "clarity", remove_first_dummy = TRUE) %>%
  fastDummies::dummy_cols(select_columns = "color", remove_first_dummy = TRUE)

diamonds_dummy
```
# 6. Going forward we’ll let R handle dummy variable creation for categorical predictors in regression fitting (remember lm() will generate the correct numbers of dummy levels automatically, absorbing one of the levels into the intercept as a reference level)

i. First, we’ll start with simple linear regression. Regress price on carat and check the regression diagnostics.

```{r}
model <- lm(carat ~ price, data = diamonds_trim)

autoplot(model)
```

```{r}
summary(model)
```






